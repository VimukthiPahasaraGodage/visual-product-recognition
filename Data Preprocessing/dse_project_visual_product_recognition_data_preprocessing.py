# -*- coding: utf-8 -*-
"""DSE Project - Visual Product Recognition - Data Preprocessing.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/16s7AUBgDMXhwKZQvY1Yoo3oIQra-I8kx
"""

from google.colab import drive
drive.mount('/content/gdrive')

# Commented out IPython magic to ensure Python compatibility.
# %%capture
# !unzip /content/gdrive/MyDrive/archive.zip -d /content/training-dataset/

!mv "/content/training-dataset/train/train" "/content/"
!mv "/content/training-dataset/test/test" "/content/"

!rmdir "/content/training-dataset/train"
!rmdir "/content/training-dataset/test"

!mv "/content/train" "/content/training-dataset/"
!mv "/content/test" "/content/training-dataset/"

import os
import shutil
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import random
from sklearn.utils import shuffle
import cv2
from pathlib import Path
from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input
from sklearn.metrics.pairwise import cosine_similarity

source_dir = '/content/training-dataset/test/'
destination_dir = '/content/training-dataset/train/'

images = [f for f in os.listdir(source_dir) if f.lower().endswith('.jpg')]

for image in images:
    source_path = os.path.join(source_dir, image)
    destination_path = os.path.join(destination_dir, image)
    shutil.move(source_path, destination_path)

!rmdir "/content/training-dataset/test"

training_dataset_train = pd.read_csv('training-dataset/train.csv', low_memory=False)
training_dataset_test = pd.read_csv('training-dataset/test.csv', low_memory=False)

train_df = pd.concat([training_dataset_train, training_dataset_test], ignore_index=True)

train_df.to_csv('trainn.csv', index=False)

display(train_df.head())

train_df.shape



# Create an empty DataFrame to store the results
results_1 = pd.DataFrame(columns=['image1', 'image2', 'similarity'])

# Create a copy of the train_df DataFrame
train_df_copy = train_df.copy()

# Create an empty set to store the unique class names
unique_classes = set()

# Get the number of iterations as manual input from the user
num_iterations = 250000

# Create a list to store the individual DataFrames
dfs = []
available_classes = train_df_copy['class'].unique()

for i in range(num_iterations):
    # Filter train_df to get rows with the same class
    class_choice = random.choice(available_classes)
    unique_classes.update([class_choice])
    class_rows = train_df_copy[train_df_copy['class'] == class_choice]

    if len(class_rows) >= 2:
        random_indices = random.sample(class_rows.index.tolist(), 2)
        random_rows = class_rows.loc[random_indices]

        # Get the image names and classes
        image1_name = random_rows.iloc[0]['name']
        image2_name = random_rows.iloc[1]['name']
        class1 = random_rows.iloc[0]['class']
        class2 = random_rows.iloc[1]['class']

        # Determine whether the classes are the same
        if class1 == class2:
            similarity = 1
        else:
            similarity = 0

        # Create a new DataFrame with the information
        result_df = pd.DataFrame({
            'image1': [image1_name],
            'image2': [image2_name],
            'similarity': [similarity]
        })

        # Append the result DataFrame to the list
        dfs.append(result_df)

        # # Remove the selected rows from train_df_copy
        # train_df_copy.drop(random_indices[0], inplace=True)

        # # Remove the class from available_classes if it has <= 1 rows
        # if len(class_rows) <= 1:
        #     available_classes = [c for c in available_classes if c != class_choice]

# Concatenate all individual DataFrames into the final results DataFrame
results_1 = pd.concat(dfs, ignore_index=True)

print(f"Generated {num_iterations} similarity pairs and saved to 'same_image_similarity_results.csv'")

print(results_1)

num_unique_classes = len(unique_classes)
print(f"Number of unique classes: {num_unique_classes}")

# Create an empty DataFrame to store the results
results_2 = pd.DataFrame(columns=['image1', 'image2', 'similarity'])

# Create a copy of the train_df DataFrame
train_df_copy = train_df.copy()

# Create an empty set to store the unique class names
unique_classes = set()

# Get the number of iterations as manual input from the user
num_iterations = 750000

# Create a list to store the individual DataFrames
dfs = []

for i in range(num_iterations):
    # Choose two random rows from the DataFrame
    random_indices = random.sample(range(len(train_df)), 2)
    random_rows = train_df.iloc[random_indices]

    # Get the image names and classes
    image1_name = random_rows.iloc[0]['name']
    image2_name = random_rows.iloc[1]['name']
    class1 = random_rows.iloc[0]['class']
    class2 = random_rows.iloc[1]['class']

    unique_classes.update([class1])
    unique_classes.update([class2])

    # Determine whether the classes are the same
    if class1 == class2:
        similarity = 1
    else:
        similarity = 0

    # Create a new DataFrame with the information
    result_df = pd.DataFrame({
        'image1': [image1_name],
        'image2': [image2_name],
        'similarity': [similarity]
    })

    # Append the result DataFrame to the list
    dfs.append(result_df)



# Concatenate all individual DataFrames into the final results DataFrame
results_2 = pd.concat(dfs, ignore_index=True)



print(f"Generated {num_iterations} similarity pairs and saved to 'random_image_similarity_results.csv'")

print(results_2)

# Count the occurrences of 0s and 1s in the 'similarity' column
similarity_counts = results_2['similarity'].value_counts()

# Print the counts
print("Count of 0s:", similarity_counts.get(0, 0))
print("Count of 1s:", similarity_counts.get(1, 0))

num_unique_classes = len(unique_classes)
print(f"Number of unique classes: {num_unique_classes}")

similarity_results= pd.concat([results_1, results_2], ignore_index=True)
similarity_results = shuffle(similarity_results)
similarity_results.to_csv('similarity_results.csv', index=False)

print(similarity_results)

# Count the occurrences of 0s and 1s in the 'similarity' column
similarity_counts = similarity_results['similarity'].value_counts()

# Print the counts
print("Count of 0s:", similarity_counts.get(0, 0))
print("Count of 1s:", similarity_counts.get(1, 0))

